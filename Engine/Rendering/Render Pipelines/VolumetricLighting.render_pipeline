//Declare uniform buffer includes.
IncludeUniformBuffer(Camera);
IncludeUniformBuffer(General);
IncludeUniformBuffer(RenderingConfiguration);
IncludeUniformBuffer(World);

//Declare storage buffer includes.
IncludeStorageBuffer(Lighting);

//Declare shader function library includes.
IncludeShaderFunctionLibrary(BlueNoise);
IncludeShaderFunctionLibrary(Camera);
IncludeShaderFunctionLibrary(Lighting);
IncludeShaderFunctionLibrary(Noise);
IncludeShaderFunctionLibrary(RenderingConfiguration);
IncludeShaderFunctionLibrary(VolumetricLighting);

//Declare input render targets.
InputRenderTarget(SceneFeatures2Half /* Identifier */, NEAREST /* Magnification Filter */, NEAREST /* Mipmap Mode */, CLAMP_TO_EDGE /* Address Mode */);

//Declare output render targets.
OutputRenderTarget(VolumetricLighting);

//Declare render resolution.
RenderResolution(MAIN_HALF);

//Set the load/store operators.
ColorStoreOperator(STORE);

//Set the topology.
Topology(TRIANGLE_FAN);

//Subscribe to input streams.
SubscribeToInputStream(Viewport);

//The vertex shader.
IncludeCommonVertexShader(ViewportScreenCoordinate);

//The fragment shader.
Fragment
{
    //Declare input parameters.
    InputParameter(vec2, InTextureCoordinate);

    //Constants.
    #define SCATTERING (vec3(0.8f, 0.9f, 1.0f) * 0.125f * 0.125f)
    #define NUMBER_OF_SAMPLES (8)
    #define SAMPLE_RECIPROCAL (1.0f / NUMBER_OF_SAMPLES)
    #define HALF_SAMPLE_RECIPROCAL (SAMPLE_RECIPROCAL / 2)

    //Load the scene features.
	vec4 scene_features_2 = texture(SceneFeatures2Half, InTextureCoordinate);

    //Calculate the start position.
    vec3 start_position = CAMERA_WORLD_POSITION;

    //Retrieve all properties.
	vec3 world_position = CalculateWorldPosition(InTextureCoordinate, scene_features_2.w);
	float hit_distance = length(world_position - start_position);
	float hit_distance_reciprocal = 1.0f / hit_distance;

    //Generate the ray direction.
	vec3 ray_direction = (world_position - start_position) * hit_distance_reciprocal;

    //Set up the offsets.
    float offsets[NUMBER_OF_SAMPLES];

    for (uint i = 0; i < NUMBER_OF_SAMPLES; ++i)
    {
        offsets[i] = HALF_SAMPLE_RECIPROCAL + SAMPLE_RECIPROCAL * float(i);
    }

    //Jitter the offsets a bit.
    for (uint i = 0; i < NUMBER_OF_SAMPLES; i += 4)
    {
        vec4 blue_noise_texture_sample = (SampleBlueNoiseTexture(uvec2(FRAGMENT_COORDINATE.xy), i / 4) - 0.5f) * (SAMPLE_RECIPROCAL - FLOAT32_EPSILON);
        
        offsets[i * 4 + 0] += blue_noise_texture_sample.x;
        offsets[i * 4 + 1] += blue_noise_texture_sample.y;
        offsets[i * 4 + 2] += blue_noise_texture_sample.z;
        offsets[i * 4 + 3] += blue_noise_texture_sample.w;
    }

    //Bias the offsets a bit to to be closet to the camera.
    for (uint i = 0; i < NUMBER_OF_SAMPLES; ++i)
    {
        offsets[i] *= offsets[i];
    }

    //Calculate the volumetric lighting.
	vec3 volumetric_lighting = vec3(0.0f);
    float transmittance = 1.0f;

    for (uint sample_index = 0; sample_index < NUMBER_OF_SAMPLES; ++sample_index)
    {
        //Calculate the current sample position and hit distance.
        float previous_offset = sample_index > 0 ? offsets[sample_index - 1] : 0.0f;
        float current_offset = offsets[sample_index];
        vec3 sample_position = mix(start_position, world_position, current_offset);
        float sample_hit_distance = (hit_distance * current_offset) - (hit_distance * previous_offset);

        //Cache the extinction.
        float extinction = GetExtinctionAtPosition(sample_position);

        //Calculate the attenuation factor.
        float attenuation_factor = exp(-extinction * sample_hit_distance);

        //Add ambient lighting.
        {
            //Go with an average of the sky color.
            float ambient_attenuation = mix(CalculateAttenuationInDirection(sample_position, vec3(0.0f, 1.0f, 0.0f), FAR_PLANE), CalculateAttenuationInDirection(sample_position, vec3(0.0f, -1.0f, 0.0f), FAR_PLANE), 0.5f);
            vec3 scattering = mix(UPPER_SKY_COLOR, LOWER_SKY_COLOR, 0.5f) * SCATTERING * (1.0f / (4.0f * 3.14f)) * ambient_attenuation;
            vec3 scattering_integral = (scattering - scattering * attenuation_factor) / max(extinction, FLOAT32_EPSILON);
            volumetric_lighting += transmittance * scattering_integral;
        }

        //Iterate over all lights.
        for (uint i = 0; i < LIGHTING_HEADER._NumberOfLights; ++i)
        {
            //Unpack the light.
		    Light light = UnpackLight(i);

            //Only care if this light is volumetric.
            if (TEST_BIT(light._LightProperties, LIGHT_PROPERTY_VOLUMETRIC_BIT))
            {
                //Calculate the light radiance.
                vec3 light_radiance = light._Color * light._Intensity;

                switch (light._LightType)
                {
                    case LIGHT_TYPE_DIRECTIONAL:
                    {
                        //float light_attenuation = CalculateAttenuationInDirection(sample_position, -light._TransformData1, FAR_PLANE * 2.0f);
                        float light_attenuation = CalculateAttenuationInDirection(sample_position, -light._TransformData1, hit_distance);
                        vec3 scattering = light_radiance * SCATTERING * HenyeyGreensteinPhaseFunction(ray_direction, light._TransformData1) * light_attenuation;
                        
                        //Cast a screen space ray.
                        float screen_space_occlusion = 1.0f;

                        if (VOLUMETRIC_SHADOWS_MODE == VOLUMETRIC_SHADOWS_MODE_SCREEN_SPACE)
                        {
                            //Calculate up the screen space position.
                            vec3 screen_space_position = CalculateScreenPosition(sample_position);

                            //Calculate the screen space light position.
                            vec3 screen_space_light_position;

                            {
                                vec3 light_world_position = (CAMERA_WORLD_POSITION + -light._TransformData1 * FAR_PLANE);
                                vec4 view_space_position = WORLD_TO_CLIP_MATRIX * vec4(light_world_position, 1.0f);
                                float view_space_position_coefficient_reciprocal = 1.0f / view_space_position.w;
                                view_space_position.xyz *= view_space_position_coefficient_reciprocal;

                                view_space_position.xy = clamp(view_space_position.xy, vec2(-1.0f), vec2(1.0f));
                                view_space_position.xy = view_space_position.xy * 0.5f + 0.5f;
                                view_space_position.z = LinearizeDepth(view_space_position.z);
    
                                screen_space_light_position = view_space_position.xyz;
                            }

                            //Calculate the screen factor.
                            float screen_factor = max(dot(ray_direction, -light._TransformData1), 0.0f);

                            //Do a bunch of tests and accumulate the occlusion
                            float occlusion = 0.0f;

                            for (uint sub_sample_index = 0; sub_sample_index < 4; ++sub_sample_index)
                            {
                                //Calculate the expected screen space position.
                                vec3 expected_screen_space_position = mix(screen_space_position, screen_space_light_position, InterleavedGradientNoise(uvec2(FRAGMENT_COORDINATE.xy), FRAME + 1 + sample_index + sub_sample_index));
                        
                                //Sample the depth.
                                float sample_depth = LinearizeDepth(texture(SceneFeatures2Half, expected_screen_space_position.xy).w);
                        
                                //Set the occlusion.
                                occlusion += float(sample_depth > expected_screen_space_position.z) * 0.25f;
                            }

                            //Bias the occlusion a bit.
                            occlusion *= occlusion * occlusion * occlusion * occlusion;
                            
                            screen_space_occlusion = mix(1.0f, occlusion, screen_factor);
                        }

                        scattering *= screen_space_occlusion;
                        
                        vec3 scattering_integral = (scattering - scattering * attenuation_factor) / max(extinction, FLOAT32_EPSILON);
                        volumetric_lighting += transmittance * scattering_integral;
                
                        break;
                    }
                }
            }
        }

        //Update the transmittance.
        transmittance *= attenuation_factor;
    }

    //Write the fragment.
    OutputFragment(VolumetricLighting, vec4(volumetric_lighting, 1.0f));
}